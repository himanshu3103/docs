{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "FI_API_KEY=\"d1533c4e62b64efd926355e22350cd11\"\n",
    "FI_SECRET_KEY=\"a508a3c6cf7647cda67197af574d2b45\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/apple/miniconda3/lib/python3.12/site-packages/pydantic/_internal/_fields.py:192: UserWarning: Field name \"json\" in \"RequestConfig\" shadows an attribute in parent \"BaseModel\"\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from fi.prompt.client import PromptClient\n",
    "from fi.prompt.types import ModelConfig, PromptTemplate, SystemMessage, UserMessage"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a prompt from scratch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "system_prompt = \"You are a customer service assistant, help customers answer their queries\"\n",
    "user_prompt1 = '''\n",
    "You are a Tier-1 customer support agent for {{product_line}}.  \n",
    "**Task:**  \n",
    "1. Classify the customer's issue into one of these categories:  \n",
    "   - Password reset  \n",
    "   - Account unlock  \n",
    "   - Basic troubleshooting (e.g., {{error_code}})  \n",
    "   - Billing inquiry  \n",
    "   - Escalate to Tier-2  \n",
    "\n",
    "2. **If the issue is routine (first three categories):**  \n",
    "   - Respond in a {{customer_tone}} tone.  \n",
    "   - Provide a step-by-step resolution using ONLY approved knowledge base articles.  \n",
    "   - Include:  \n",
    "     - Clear instructions (max 5 steps).  \n",
    "     - Safety disclaimer: \"Do not share personal data in public forums.\"  \n",
    "     - Closing question: \"Does this resolve your issue?\"  \n",
    "\n",
    "3. **If escalation is needed:**  \n",
    "   - Acknowledge urgency: \"I'll prioritize this with our specialists.\"  \n",
    "   - List NEXT STEPS: \"Expect a response within 1 hour via {{preferred_contact_method}}.\"  \n",
    "\n",
    "**Rules:**  \n",
    "- Never invent solutions outside the knowledge base.  \n",
    "- Use bullet points for readability.  \n",
    "- Mirror the customer's language style (formal/casual).  \n",
    "'''\n",
    "user_prompt2 = \"{{userquery}}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_multiple_variables_prompt():\n",
    "    template = PromptTemplate(\n",
    "        name=\"csat_agent\",\n",
    "        messages=[\n",
    "            SystemMessage(content=system_prompt),\n",
    "            UserMessage(content=user_prompt1),\n",
    "            UserMessage(content=user_prompt2)\n",
    "        ],\n",
    "        model_configuration=ModelConfig(\n",
    "            model_name=\"gpt-4o-mini\",\n",
    "            temperature=0.7\n",
    "        )\n",
    "    )\n",
    "    \n",
    "    client = PromptClient(template=template, fi_api_key=FI_API_KEY, fi_secret_key=FI_SECRET_KEY, fi_base_url=\"https://dev.api.futureagi.com\")\n",
    "    return client.create()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Template not found in the backend. Create a new template before running.\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":    \n",
    "    multi_var_client = create_multiple_variables_prompt()\n",
    "    response = multi_var_client.run(variables={\n",
    "        \"product_line\": \"Phone\",\n",
    "        \"error_code\": \"400\",\n",
    "        \"customer_tone\": \"Polite\",\n",
    "        \"preferred_contact_method\": \"Email\",\n",
    "        \"userquery\": \"Phone not starting\"\n",
    "    })"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate a prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Template not found in the backend. Create a new template before running.\n",
      "\n",
      "Generated content for requirement: Add a friendly greeting at the start\n",
      "Latest message: You are an AI assistant tasked with adding a friendly greeting to the beginning of a given text. Your goal is to create a welcoming and positive first impression while maintaining the original content's integrity.\n",
      "\n",
      "Follow these steps to complete the task:\n",
      "\n",
      "1. Read the provided text carefully:\n",
      "<original_text>\n",
      "{{ORIGINAL_TEXT}}\n",
      "</original_text>\n",
      "\n",
      "2. Choose a friendly, generic greeting that can work in multiple contexts. Some options include:\n",
      "   - \"Hello there!\"\n",
      "   - \"Hi, welcome!\"\n",
      "   - \"Greetings!\"\n",
      "   - \"Hey, nice to see you!\"\n",
      "\n",
      "3. Add the chosen greeting at the very beginning of the text, followed by a space.\n",
      "\n",
      "4. Ensure the greeting ends with an exclamation mark to convey friendliness and enthusiasm.\n",
      "\n",
      "5. Keep the greeting short and simple (2-4 words) to accommodate various potential use cases.\n",
      "\n",
      "6. Maintain the original content exactly as provided, without any modifications.\n",
      "\n",
      "Now, combine the chosen greeting with the original text and present the result in the following format:\n",
      "\n",
      "<modified_text>\n",
      "[Your chosen greeting followed by the original text]\n",
      "</modified_text>\n",
      "\n",
      "Remember to:\n",
      "- Place the greeting at the very beginning\n",
      "- Use a friendly and enthusiastic tone\n",
      "- Keep the original content intact\n",
      "- Ensure there's a space between the greeting and the original text\n",
      "\n",
      "Begin the task now.\n",
      "\n",
      "Generated content for requirement: Include empathy in the response\n",
      "Latest message: You are an AI assistant tasked with crafting an empathetic response. Your goal is to create a message that demonstrates understanding, compassion, and emotional intelligence. Follow these steps to create an empathetic response:\n",
      "\n",
      "1. Begin by carefully reading the context provided:\n",
      "<context>\n",
      "{{CONTEXT}}\n",
      "</context>\n",
      "\n",
      "2. Identify the key emotions, concerns, or experiences expressed in the context.\n",
      "\n",
      "3. Craft your response using the following structure:\n",
      "\n",
      "<empathetic_response>\n",
      "<acknowledgment>\n",
      "Start with a statement that acknowledges the other person's feelings or situation. Use phrases like \"I understand that you're feeling...\" or \"It sounds like you're going through...\"\n",
      "</acknowledgment>\n",
      "\n",
      "<validation>\n",
      "Validate their emotions or experience. For example, \"It's completely natural to feel that way in this situation\" or \"Anyone would find this challenging.\"\n",
      "</validation>\n",
      "\n",
      "<understanding>\n",
      "Express understanding or relate to their perspective. You can use phrases like \"I can see why you would feel...\" or \"Many people in similar situations have experienced...\"\n",
      "</understanding>\n",
      "\n",
      "<support>\n",
      "If appropriate, offer support or assistance. This could be emotional support or practical help, depending on the context. For example, \"Is there anything I can do to help?\" or \"I'm here to listen if you need to talk more about this.\"\n",
      "</support>\n",
      "\n",
      "<closing>\n",
      "End with a compassionate statement or question that shows you care about their well-being. For instance, \"How are you coping with this?\" or \"Please don't hesitate to reach out if you need further support.\"\n",
      "</closing>\n",
      "</empathetic_response>\n",
      "\n",
      "4. Review your response to ensure it:\n",
      "   - Uses a warm and caring tone throughout\n",
      "   - Avoids minimizing or dismissing the person's feelings\n",
      "   - Maintains appropriate boundaries (especially in professional contexts)\n",
      "   - Focuses on the other person's experience rather than shifting attention to yourself\n",
      "\n",
      "5. Adjust the language and tone to fit the specific context (e.g., customer service, personal communication, or professional setting).\n",
      "\n",
      "Now, craft an empathetic response based on the given context and structure.\n",
      "\n",
      "Generated content for requirement: Ask for specific details about the issue\n",
      "Latest message: You are an expert interviewer tasked with gathering specific details about an issue. Your goal is to ask targeted questions that will elicit comprehensive information about the problem at hand. Follow these steps to conduct a thorough inquiry:\n",
      "\n",
      "1. Begin by requesting a brief overview of the issue:\n",
      "<issue_overview>\n",
      "{{ISSUE_OVERVIEW}}\n",
      "</issue_overview>\n",
      "\n",
      "2. Now, systematically ask the following questions to gather detailed information. For each response, ask relevant follow-up questions to delve deeper into the specifics:\n",
      "\n",
      "a) What exactly is the issue? Describe it in detail.\n",
      "<issue_description>\n",
      "{{ISSUE_DESCRIPTION}}\n",
      "</issue_description>\n",
      "\n",
      "b) When did this issue first occur? Provide specific dates or timeframes.\n",
      "<issue_timeline>\n",
      "{{ISSUE_TIMELINE}}\n",
      "</issue_timeline>\n",
      "\n",
      "c) Where is this issue happening? Specify locations or contexts.\n",
      "<issue_location>\n",
      "{{ISSUE_LOCATION}}\n",
      "</issue_location>\n",
      "\n",
      "d) Who is affected by or involved in this issue?\n",
      "<involved_parties>\n",
      "{{INVOLVED_PARTIES}}\n",
      "</involved_parties>\n",
      "\n",
      "e) Why do you believe this issue is occurring?\n",
      "<issue_cause>\n",
      "{{ISSUE_CAUSE}}\n",
      "</issue_cause>\n",
      "\n",
      "f) How is this issue impacting you or others?\n",
      "<issue_impact>\n",
      "{{ISSUE_IMPACT}}\n",
      "</issue_impact>\n",
      "\n",
      "g) Have any attempts been made to address this issue? If so, what were they and what were the results?\n",
      "<previous_attempts>\n",
      "{{PREVIOUS_ATTEMPTS}}\n",
      "</previous_attempts>\n",
      "\n",
      "3. After each response, summarize the key points to ensure accurate understanding. Ask for clarification if needed.\n",
      "\n",
      "4. Based on the information gathered, identify any gaps or areas requiring further explanation. Ask additional questions to fill these gaps.\n",
      "\n",
      "5. Finally, ask if there's any other relevant information about the issue that hasn't been covered by the previous questions.\n",
      "<additional_information>\n",
      "{{ADDITIONAL_INFORMATION}}\n",
      "</additional_information>\n",
      "\n",
      "Now, proceed with the interview, asking these questions in order and following up as necessary to gather comprehensive details about the issue. Ensure that your tone remains professional, empathetic, and non-judgmental throughout the process. Document the responses in the provided XML tags for each question.\n",
      "\n",
      "\n",
      "Final template messages:\n",
      "system: You are a customer service representative.\n",
      "user: You are an expert interviewer tasked with gathering specific details about an issue. Your goal is to ask targeted questions that will elicit comprehensive information about the problem at hand. Follow these steps to conduct a thorough inquiry:\n",
      "\n",
      "1. Begin by requesting a brief overview of the issue:\n",
      "<issue_overview>\n",
      "{{ISSUE_OVERVIEW}}\n",
      "</issue_overview>\n",
      "\n",
      "2. Now, systematically ask the following questions to gather detailed information. For each response, ask relevant follow-up questions to delve deeper into the specifics:\n",
      "\n",
      "a) What exactly is the issue? Describe it in detail.\n",
      "<issue_description>\n",
      "{{ISSUE_DESCRIPTION}}\n",
      "</issue_description>\n",
      "\n",
      "b) When did this issue first occur? Provide specific dates or timeframes.\n",
      "<issue_timeline>\n",
      "{{ISSUE_TIMELINE}}\n",
      "</issue_timeline>\n",
      "\n",
      "c) Where is this issue happening? Specify locations or contexts.\n",
      "<issue_location>\n",
      "{{ISSUE_LOCATION}}\n",
      "</issue_location>\n",
      "\n",
      "d) Who is affected by or involved in this issue?\n",
      "<involved_parties>\n",
      "{{INVOLVED_PARTIES}}\n",
      "</involved_parties>\n",
      "\n",
      "e) Why do you believe this issue is occurring?\n",
      "<issue_cause>\n",
      "{{ISSUE_CAUSE}}\n",
      "</issue_cause>\n",
      "\n",
      "f) How is this issue impacting you or others?\n",
      "<issue_impact>\n",
      "{{ISSUE_IMPACT}}\n",
      "</issue_impact>\n",
      "\n",
      "g) Have any attempts been made to address this issue? If so, what were they and what were the results?\n",
      "<previous_attempts>\n",
      "{{PREVIOUS_ATTEMPTS}}\n",
      "</previous_attempts>\n",
      "\n",
      "3. After each response, summarize the key points to ensure accurate understanding. Ask for clarification if needed.\n",
      "\n",
      "4. Based on the information gathered, identify any gaps or areas requiring further explanation. Ask additional questions to fill these gaps.\n",
      "\n",
      "5. Finally, ask if there's any other relevant information about the issue that hasn't been covered by the previous questions.\n",
      "<additional_information>\n",
      "{{ADDITIONAL_INFORMATION}}\n",
      "</additional_information>\n",
      "\n",
      "Now, proceed with the interview, asking these questions in order and following up as necessary to gather comprehensive details about the issue. Ensure that your tone remains professional, empathetic, and non-judgmental throughout the process. Document the responses in the provided XML tags for each question.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from fi.prompt.client import PromptClient\n",
    "from fi.prompt.types import ModelConfig, PromptTemplate, SystemMessage, UserMessage\n",
    "\n",
    "def generate_prompt_content():\n",
    "    template = PromptTemplate(\n",
    "        name=\"csat_generate_prompt\",\n",
    "        messages=[\n",
    "            SystemMessage(content=\"You are a customer service representative.\"),\n",
    "            UserMessage(content=\"How can I help you with your {issue}?\")\n",
    "        ],\n",
    "        model_configuration=ModelConfig(\n",
    "            model_name=\"gpt-4o-mini\",\n",
    "            temperature=0.7,\n",
    "            max_tokens=1000\n",
    "        )\n",
    "    )\n",
    "\n",
    "    prompt_client = PromptClient(template=template, fi_api_key=FI_API_KEY, fi_secret_key=FI_SECRET_KEY, fi_base_url=\"https://dev.api.futureagi.com\")\n",
    "    \n",
    "    client = prompt_client.create()\n",
    "    \n",
    "    requirements = [\n",
    "        \"Add a friendly greeting at the start\",\n",
    "        \"Include empathy in the response\",\n",
    "        \"Ask for specific details about the issue\"\n",
    "    ]\n",
    "    \n",
    "    for requirement in requirements:\n",
    "        client = client.generate(requirement)\n",
    "        print(f\"\\nGenerated content for requirement: {requirement}\")\n",
    "        print(f\"Latest message: {client.template.messages[-1].content}\")\n",
    "    \n",
    "    return client\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    try:\n",
    "        generated_client = generate_prompt_content()\n",
    "        print(\"\\nFinal template messages:\")\n",
    "        for msg in generated_client.template.messages:\n",
    "            print(f\"{msg.role}: {msg.content}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error generating prompt content: {str(e)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Improve an Existing Prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Template not found in the backend. Create a new template before running.\n"
     ]
    }
   ],
   "source": [
    "from fi.prompt.client import PromptClient\n",
    "from fi.prompt.types import ModelConfig, PromptTemplate, SystemMessage, UserMessage\n",
    "\n",
    "def improve_prompt_examples():\n",
    "    \"\"\"Examples of improving prompts with different approaches\"\"\"\n",
    "\n",
    "    template = PromptTemplate(\n",
    "        name=\"customer_support_template\",\n",
    "        messages=[\n",
    "            SystemMessage(content=\"You are a customer service representative.\"),\n",
    "            UserMessage(content=\"How can I help with your {issue_type} today?\")\n",
    "        ],\n",
    "        model_configuration=ModelConfig(\n",
    "            model_name=\"gpt-4\",\n",
    "            temperature=0.7,\n",
    "            max_tokens=1000\n",
    "        )\n",
    "    )\n",
    "\n",
    "    prompt_client = PromptClient(template=template, fi_api_key=FI_API_KEY, fi_secret_key=FI_SECRET_KEY, fi_base_url=\"https://dev.api.futureagi.com\")\n",
    "    client = prompt_client.create()\n",
    "\n",
    "    # Example 1: Basic Improvement - Make Language More Professional\n",
    "    client = client.improve(\"Make the language more formal and professional\")\n",
    "    print(\"\\nAfter professional improvement:\")\n",
    "    print(f\"Latest message: {client.template.messages[-1].content}\")\n",
    "\n",
    "    # Example 2: Improve Clarity and Structure\n",
    "    client = client.improve(\n",
    "        \"Add clear structure with greeting, issue identification, and next steps\"\n",
    "    )\n",
    "    print(\"\\nAfter structural improvement:\")\n",
    "    print(f\"Latest message: {client.template.messages[-1].content}\")\n",
    "\n",
    "    # Example 3: Add Empathy and Personalization\n",
    "    client = client.improve(\n",
    "        \"Add empathetic language and personalization while maintaining professionalism\"\n",
    "    )\n",
    "    print(\"\\nAfter empathy improvement:\")\n",
    "    print(f\"Latest message: {client.template.messages[-1].content}\")\n",
    "\n",
    "    # Example 4: Optimize for Specific Use Case\n",
    "    client = client.improve(\n",
    "        \"Optimize for technical support issues with relevant terminology\"\n",
    "    )\n",
    "    print(\"\\nAfter use-case optimization:\")\n",
    "    print(f\"Latest message: {client.template.messages[-1].content}\")\n",
    "\n",
    "    return client\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    try:\n",
    "        improved_client = improve_prompt_examples()\n",
    "        print(\"\\nFinal improved template:\")\n",
    "        for msg in improved_client.template.messages:\n",
    "            print(f\"{msg.role}: {msg.content}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error improving prompt: {str(e)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
